{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 3 - VECTOR SPACE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install nltk package\n",
    "* models/**punkt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input\n",
    "* **data**: dictionary\n",
    "    * ex: {'0': { 'title': ..., 'link': ..., 'content': ..., 'summary': ... }, '1': {...}, ... }\n",
    "* stored in **orig_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import json\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import copy\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# file name - get from crawler\n",
    "filename = 'crawler.txt'\n",
    "\n",
    "# load data\n",
    "with open(filename, 'r', encoding='utf8') as json_file:\n",
    "    orig_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load stopwords\n",
    "* open Vietnamese stopwords file (stopwords.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(filename='stopwords.txt'):\n",
    "    stop_words = []\n",
    "    with open(filename, 'r', encoding='utf8') as file:\n",
    "        stop_words = file.readlines()\n",
    "    stop_words = [item.strip() for item in stop_words] \n",
    "    return stop_words\n",
    "\n",
    "stop_words = load_stopwords()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "* **Description**: concatenate all content fields\n",
    "    * remove **punctuation**\n",
    "    * remove **endline**\n",
    "    * remove **spaces** - generated by beautifulsoup\n",
    "    * transform **lowercase**\n",
    "    * remove **trailing spaces**\n",
    "* **Input**: orig_data\n",
    "* **Output**: dictionary with content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    global stop_words, orig_data\n",
    "    data = {}\n",
    "    keys = ['title', 'content', 'summary']\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    for item in orig_data:\n",
    "        data[item] = ''\n",
    "        for key in keys:\n",
    "            data[item] += orig_data[item][key] + ' '\n",
    "        data[item] = word_tokenize(data[item].translate(translator).replace('\\n', ' ').replace('\\xa0', ' ').lower().strip())\n",
    "        data[item] = [w for w in data[item] if w not in stop_words]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate terms from given documents\n",
    "* **Input**: preprocessing data\n",
    "* **Output**: set of terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terms(data):\n",
    "    terms = set()\n",
    "    for key in data:\n",
    "        for item in data[key]:\n",
    "            terms.add(item)\n",
    "    return list(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tf table\n",
    "* **Input**: preprocessing data and set of terms\n",
    "* **Output**: tf table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_tf_table(docs, terms):\n",
    "    tf_table = np.zeros((len(terms), len(docs)))\n",
    "    \n",
    "    # doc_id is string since it's json key\n",
    "    for doc_id in docs:\n",
    "        for term_id, term in enumerate(terms):\n",
    "            tf_table[term_id][int(doc_id)] = docs[doc_id].count(term)\n",
    "    tf_table = (1+np.ma.log10(tf_table)).filled(0)\n",
    "    return tf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create idf table\n",
    "* **Input**: preprocessing data and set of terms\n",
    "* **Output**: idf table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_idf_table(docs, terms):\n",
    "    idf_table = np.zeros(len(terms))\n",
    "    for doc_id in docs:\n",
    "        for term_id, term in enumerate(terms):\n",
    "            if term in docs[doc_id]:\n",
    "                idf_table[term_id] += 1\n",
    "    idf_table = (1+np.ma.log10(len(docs)/(idf_table+1))).filled(0).reshape(-1,1)\n",
    "    return idf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tf-idf table\n",
    "* **Input**: preprocessing data and set of terms\n",
    "* **Output**: tf-idf table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf_table(docs, terms):\n",
    "    tf = create_tf_table(docs, terms)\n",
    "    idf = create_idf_table(docs, terms)\n",
    "    tf_idf = tf * idf\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search\n",
    "* **Input**: query, number of documents that you want to show, tf-idf table (all docs), terms\n",
    "* **Output**: list of tuples containing index and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by the second element in pair\n",
    "def sort_by_val(item):\n",
    "    return item[1]\n",
    "\n",
    "def search(query, rank, table, terms):\n",
    "    \n",
    "    # remove trailing spaces, lowercase\n",
    "    query = query.lower().strip().split(' ')\n",
    "    \n",
    "    # calculate tf_idf of query\n",
    "    tf_idf = create_tf_idf_table({\"0\": query}, terms)\n",
    "    \n",
    "    # score\n",
    "    score = table.T.dot(tf_idf.reshape(-1))\n",
    "        \n",
    "    # remove score=0\n",
    "    score = sorted([(idx, val) for idx, val in enumerate(score) if val], reverse=True, key=sort_by_val)\n",
    "        \n",
    "    return score[:rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export result\n",
    "* **Input**: list of documents' index and score\n",
    "* Default **filename** is output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(result, filename='output.txt'):\n",
    "    global orig_data\n",
    "    with open(filename, 'w', encoding='utf8') as file:\n",
    "        file.write('Total: ' + str(len(result)) + '\\n')\n",
    "        for i in result:\n",
    "            file.write('Document ID - Score: ' + str(i) + '\\n')\n",
    "            for key in orig_data[str(i[0])]:\n",
    "                file.write(key + ':\\n' + orig_data[str(i[0])][key] + '\\n')\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print result\n",
    "* Print document ID and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(result):\n",
    "    print('Document ID - Score')\n",
    "    for item in result:\n",
    "        print(item[0], '-', item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "* preprocessing data\n",
    "* generate set of terms\n",
    "* create tf-idf table from data and terms\n",
    "* input query\n",
    "* input the number of result that you want to show\n",
    "* search query in documents (calculate tf-idf of query)\n",
    "* export result\n",
    "* print on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input query: đoàn tàu đánh cá\n",
      "The number of results you want to show: 10\n",
      "Document ID - Score\n",
      "1 - 6.177126557806552\n",
      "0 - 5.113319555842285\n",
      "20 - 3.5230749795061937\n",
      "3 - 3.26213764425216\n",
      "16 - 3.2103411340860672\n",
      "26 - 2.418853632128971\n",
      "25 - 2.233520818524947\n",
      "13 - 1.7103760357302962\n",
      "8 - 1.63106882212608\n",
      "10 - 1.3146322847517478\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # preprocessing data from orig_data\n",
    "    data = preprocessing()\n",
    "    \n",
    "    # get all terms of data\n",
    "    terms = get_terms(data)\n",
    "    \n",
    "    # create tf-idf table\n",
    "    table = create_tf_idf_table(data, terms)\n",
    "    \n",
    "    # input query. Ex: đoàn tàu đánh cá\n",
    "    query = input('Input query: ')\n",
    "    \n",
    "    # input the number of results you want to show\n",
    "    rank = input('The number of results you want to show: ')\n",
    "    # convert to int\n",
    "    rank = int(rank)\n",
    "    \n",
    "    # search\n",
    "    result = search(query, rank, table, terms)\n",
    "    \n",
    "    # print result\n",
    "    print_result(result)\n",
    "    \n",
    "    # export\n",
    "    export(result)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
